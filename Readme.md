# **모두를 위한 딥 러닝**

## [Session 2](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session2)
>__Linear Regression 의 개념__ <br>
<pre>1. Linear Regression의 Hypothesis 와 cost 
2. Tensorflow로 간단한 linear regression을 구현 (new)</pre>
## [Session 3](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session3)
>__Linear Regression cost 함수 최소화__ <br>
<pre>1. Linear Regression의 cost 최소화 알고리즘의 원리 
2. Linear Regression 의 cost 최소화의 TensorFlow 구현(new) (new)</pre>
## [Session 4](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session4)
>__여러개의 입력(feature)의 Linear Regression__ <br>
<pre>1. multi-variable linear regression (new)
2. lab 04-1: multi-variable linear regression을 TensorFlow에서 구현하기
3. lab 04-2: TensorFlow로 파일에서 데이타 읽어오기 (new)</pre>
## [Session 5](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session5)
>__Logistic (Regression) Classification__ <br>
<pre>1. 	Logistic Classification의 가설 함수 정의 
2. 	Logistic Regression의 cost 함수 설명
3. TensorFlow로 Logistic Classification의 구현하기(new)</pre>
## [Session 6](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session6)
>__Softmax Regression (Multinomial Logistic Regression)__ <br>
<pre>1. Multinomial 개념 소개 
2. Cost 함수 소개
3. lab 06-1: TensorFlow로 Softmax Classification의 구현하기 (new)
4. lab 06-2: TensorFlow로 Fancy Softmax Classification의 구현하기 (new)	</pre>
## [Session 7](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session7)
>__Neural Network 1: XOR 문제와 학습방법, Backpropagation__ <br>
<pre>1. 학습 rate, Overfitting, 그리고 일반화 (Regularization) 
2. Training/Testing 데이타 셋
3. lab 07-1: training/test dataset, learning rate, normalization (new)
4. lab 07-2: Meet MNIST Dataset (new)	</pre>
## [Session 9](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session9)
>__Neural Network 1: XOR 문제와 학습방법, Backpropagation__ <br>
<pre>1. XOR 문제 딥러닝으로 풀기 
2. 딥넷트웍 학습 시키기 (backpropagation)
3. Lab 9-1: XOR을 위한 텐스플로우 딥넷트웍 (new)
4. Lab 9-2: Tensor Board로 딥네트웍 들여다보기 (new)</pre>
## [Session 10](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session10)
>__ReLU and 초기값 정하기 (2006/2007 breakthrough)__ <br>
<pre>1. XSigmoid 보다 ReLU가 더 좋아 
2. Weight 초기화 잘해보자
3. Dropout 과 앙상블
4. 레고처렴 넷트웍 모듈을 마음껏 쌓아 보자
5. Lab 10: 딥러닝으로 MNIST 98%이상 해보기(new)</pre>
## [Session 11](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session11)
>__Convolutional Neural Networks__ <br>
<pre>1. 	ConvNet의 Conv 레이어 만들기 
2. ConvNet Max pooling 과 Full Network
3. Google Cloud ML with Examples 1
4. ConvNet의 활용 예</pre>
## [Session 12](https://github.com/GoodLuckDay/inflearn-machin_learning/tree/master/Session12)
>__Recurrent Neural Network__ <br>
<pre>1. NN의 꽃 RNN 이야기
2. Lab 12-1 RNN – Basic (new)
3. Lab 12-2 RNN – Hi Hello Training (new)
4. Lab12-4: Stacked RNN + Softmax Layer (new)
5. Lab12-5: Dynamic RNN (new)
6. 	Lab12-6: RNN with Time Series Data (new)</pre>